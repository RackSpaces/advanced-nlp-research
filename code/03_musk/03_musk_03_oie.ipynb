{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"http://hilpisch.com/tpq_logo.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Dow Jones DNA NLP Case Study\n", "\n", "_Based on news articles related to Elon Musk, Twitter & Tesla._\n", "\n", "**Information Extraction**\n", "\n", "Dr Yves J Hilpisch | Michael Schwed\n", "\n", "The Python Quants GmbH"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Imports"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "sys.path.append('../../modules')"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import nltk\n", "import pandas as pd\n", "import soiepy.main as ie\n", "import nlp_functions as nlp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Snapshot Data"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["project = 'musk_100'"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["abs_path = os.path.abspath('../../')"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["data_path = os.path.join(abs_path, 'data_musk')"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["snapshot_path = os.path.join(data_path, 'snapshot')"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["fn = os.path.join(snapshot_path, 'snapshot_{}.h5'.format(project))"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["raw = pd.read_hdf(fn, 'data')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preprocessing"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["CPU times: user 246 ms, sys: 7.59 ms, total: 253 ms\n", "Wall time: 252 ms\n"]}], "source": ["%time raw['body'] = raw['body'].apply(nlp.clean_up_text) "]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["data = raw['body'].values.tolist()  "]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n", "Wall time: 199 ms\n"]}], "source": ["%%time\n", "s = [nltk.sent_tokenize(a) for a in data]  \n", "s = [_ for sl in s for _ in sl]  "]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["['after six years of reflection, he returned to the subject.',\n", " 'the last several years have taught me that they are indeed reasonably maligned, musk wrote in an oct. 4 tweet.']"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["s[:2]"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["token_path = os.path.join(data_path, 'tokens')  \n", "if not os.path.isdir(token_path):\n", "    os.mkdir(token_path)"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["fn = os.path.join(token_path, 'tokens_{}_{}.txt')  "]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["steps = 250\n", "for c, i in enumerate(range(0, len(s), steps)):\n", "    with open(fn.format(project, c), 'w') as f:\n", "        f.writelines([_ + '\\n' for _ in s[i:i + steps - 1]])  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Relations"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["results_path = os.path.join(data_path, 'results')  \n", "if not os.path.isdir(results_path):\n", "    os.mkdir(results_path)\n", "fnr = os.path.join(results_path, 'relations_{}.h5'.format(project))  "]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["fl = sorted(os.listdir(token_path))\n", "d = pd.DataFrame()\n", "fno = len(fl)"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["CPU times: user 18.7 ms, sys: 292 \u00b5s, total: 19 ms\n", "Wall time: 17.2 ms\n"]}], "source": ["%%time\n", "try:\n", "    d = pd.read_hdf(fnr, 'raw')  \n", "except:\n", "    for i, fn in enumerate(fl):\n", "        filename = os.path.join(token_path, fn)\n", "        msg = 'Processing file {} of {} \\r'\n", "        print(msg.format(i + 1, fno), end='')\n", "        r = ie.stanford_ie(filename, verbose=False)  \n", "        dt = pd.DataFrame(r)\n", "        if len(d) == 0:\n", "            d = dt\n", "        else:\n", "            d = pd.concat((d, dt), ignore_index=True)"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["d = d.iloc[:, :3]"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["d.columns = ['Node1', 'Relation', 'Node2']"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"data": {"text/plain": ["11385"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["len(d)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Post Processing"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["data = d.copy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Basic Processing"]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": ["data = data.applymap(lambda s: s.strip())  "]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": ["data = data[data.applymap(lambda s: not s in nlp.stop_words)].dropna()  "]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": ["data = data[data.applymap(lambda s: not s.startswith('http'))].dropna()  "]}, {"cell_type": "code", "execution_