{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"http://hilpisch.com/tpq_logo.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Dow Jones DNA NLP Case Study\n", "\n", "_Based on news articles related to Elon Musk, Twitter & Tesla._\n", "\n", "**Basic Techniques and Algorithms**\n", "\n", "Dr Yves J Hilpisch\n", "\n", "The Python Quants GmbH"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Imports"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "sys.path.append('../../modules')\n", "import warnings; warnings.simplefilter('ignore')"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import nltk\n", "import pprint\n", "import collections\n", "import pandas as pd\n", "from pylab import plt\n", "import nlp_functions as nlp\n", "from sklearn.cluster import KMeans\n", "from sklearn.decomposition import NMF\n", "from gensim.summarization import keywords\n", "from gensim.summarization.summarizer import summarize\n", "from nltk.sentiment.vader import SentimentIntensityAnalyzer"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# to be executed once\n", "# nltk.download('punkt')\n", "# nltk.download('wordnet')\n", "# nltk.download('stopwords')\n", "# nltk.download('vader_lexicon')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Raw Data"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["project = 'musk_100'"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["abs_path = os.path.abspath('../../')"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["data_path = os.path.join(abs_path, 'data_musk')"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["snapshot_path = os.path.join(data_path, 'snapshot')"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["fn = os.path.join(snapshot_path, 'snapshot_{}.h5'.format(project))"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["raw = pd.read_hdf(fn, 'data')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Selection"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["sel = raw[raw['company_codes_about'].apply(\n", "            lambda s: s.find('teslmi') != -1)]  "]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["titles = sel['title']  "]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["dates = sel['publication_date'].values.tolist()  "]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["dates = [pd.Timestamp(date * 1000000) for date in dates]  "]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["data = sel['body'].values.tolist()  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic Text Analytics"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["tokens = nltk.word_tokenize(' '.join(data))  "]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["text = nltk.Text(tokens)  "]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"data": {"text/plain": ["526"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["text.count('Tesla')"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": ["96"]}, "execution_count": 18, "metadata